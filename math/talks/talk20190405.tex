\environment env-talks


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is where the document starts.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\starttext

\startfrontmatter

%%%%%%%%%%%%%%%%
% Front matter %
%%%%%%%%%%%%%%%%

\setupbackgrounds[page][
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-0}]
\startcolor[\getvariable{document}{color-foreground-0}]    % text color


% \startmode [handout]
% \startcolumns
% \stopmode


% Introduction
\startcolor [\getvariable{document}{color-foreground-0}]    % text color


\startmode [presentation]

\startslide

\startalign [middle]

	{\tfd
		\color[\getvariable{document}{color-foreground-1}]{Generalization of stochastic calculus}\\
		and its applications in\\
		\color[\getvariable{document}{color-foreground-2}]{large deviations theory}}

	\blank[2*line]

	{\tfb \getvariable{document}{author}}

	\blank[line]

	{\tfa \getvariable{document}{date}}

	\blank[2*line]

	Advisors

	\color[\getvariable{document}{color-foreground-1}]{Prof Hui-Hsiung Kuo}

	\color[\getvariable{document}{color-foreground-2}]{Prof Padmanabhan Sundar}

\stopalign

\stopslide


% Table of contents
\startslide[title={Outline}]
	\placecontent
\stopslide
\stopmode

% \startmode [manuscript]

% This presentation is going to be on two topics:
% \startitemize[n,nowhite,after]
% 	\item  Generalization of stochastic integrals developed primarily by Professor H.-H. Kuo
% 	\item  Applications of generalization in large deviations theory
% \stopitemize

% \stopmode

\stopfrontmatter



\startbodymatter

%%%%%%%%%%%%%%%%
% Introduction %
%%%%%%%%%%%%%%%%

\setupbackgrounds[page][
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-0}]
\startcolor[\getvariable{document}{color-foreground-0}]    % text color

\startsection[title={Introduction and motivation}, reference=sec:introduction]


\startmode [presentation]

\startslide [title={Quick revision and notations}]

	\startitemize[1]

		\item  Let \m{T ∈ (0, ∞)}, and denote \m{𝕋 = [0, T]} as the index set for \m{t}.

		\item  Let \m{(Ω, ℱ, ℱ_⋅, ℙ)} be a filtered probability space.

		\item  \m{B_⋅} is a Brownian motion on \m{(Ω, ℱ, ℱ_⋅, ℙ)}.

		\item  Properties of \m{B_⋅}
			\startitemize[1, columns, joinedup]
				\item  starts at 0
				\item  has independent increments
				\item  \m{B_t - B_s ∼ 𝓝(0, t - s)}
				\item  continuous paths
				\item  has \bad{unbounded linear variation \symbol[fontawesome][frown]}
				\item  has \good{bounded quadratic variation \symbol[fontawesome][smile]}
				\item  \m{𝔼(B_t B_s) = s ∧ t}
				\item  martingale
			\stopitemize

		\item  \bad{Naive stochastic integration w.r.t. \m{B_t}: not possible}.

		\item  A stochastic process \m{X_t} is called \m{\brnd[ℱ_t]}-adapted if \m{∀t}, \m{X_t} is measurable w.r.t. \m{ℱ_t}.

	\stopitemize

\stopslide

\startslide [title={Wiener integral (\m{f ∈ L^2[0, T]})}]

	\startitemize [1]

		\item  Definition
			\startitemize [n, joinedup]
				\item  Step functions \m{f = ∑_{j = 0}^{n-1} c_j 𝟙_{[t_j, t_{j + 1})}(t)}: Define \m{∫_0^T f(t) \d B_t  =  ∑_{j = 0}^{n-1} c_j Δ B_j}, where \m{Δ B_j = B_{t_{j + 1}} - B_{t_j}}.
				\item  \m{f ∈ L^2[0, T]}: Use step functions approximating \m{f} to extend the integral \important{a.s.}
			\stopitemize

		\item  Properties
			\startitemize[3, joinedup]
				\item  Linear
				% \item  Itô isometry: \m{\norm[∫_0^T f(t) \d B_t]_{L^2(Ω)}^2 = \norm[f]_{L^2[0, T]}^2}
				\item  \good{Gaussian distribution} with mean 0 and variance \m{\norm[f]_{L^2[0, T]}^2} (Itô isometry)
				\item  Corresponds to the Riemann--Stieltjes integral for \m{f ∈ C[0, T]}
			\stopitemize

		\item  The associated process: \m{I_t = ∫_0^t X_t \d B_t}
			\startitemize [3, joinedup]
				\item  continuous
				\item  martingale
			\stopitemize

		\item  Problem: Cannot integrate stochastic processes.

	\stopitemize

\stopslide


\startslide [title={Itô integral (\m{X ∈ L^2_{\text{ad}} ([0, T] × Ω)})}]

	\startitemize [1]

		\item  Definition
			\startitemize [n, joinedup]
				\item  Adapted step processes \m{X_t(ω) = ∑_{j = 0}^{n-1} ξ_j(ω) 𝟙_{[t_j, t_{j + 1})}(t)}: define \m{∫_0^T X_t \d B_t  =  ∑_{j = 0}^{n-1} ξ_j Δ B_j}.
				\item  \m{X ∈ L^2_{\text{ad}} ([0, T] × Ω)}: use step processes approximating \m{X} to extend the integral \important{in \m{L^2(Ω)}}.
			\stopitemize

		\item  Properties
			\startitemize[3, joinedup]
				\item  Linear
				\item  Mean 0 and variance \m{\norm[f]_{L^2[0, T]}^2} \good{(Itô isometry)}
				\item  For \m{X_⋅} continuous, \m{∫_0^T X_t \d B_t = \lim ∫_0^T X_{\floor[\frac{t n}{n}]} \d B_t}, for example \m{∫_0^t B_s \d B_s = \frac12 \brnd[B_t^2 - t]}
			\stopitemize

		\item  The associated process: \m{I_t = ∫_0^t X_t \d B_t}
			\startitemize [3, joinedup]
				\item  continuous
				\item  martingale
			\stopitemize

		\item  Example: \m{∫_0^T B_t \d B_t = \frac12 (B_T - T)}.

		% \item  Problem: Cannot integrate many continuous functions of \m{B_t}, for example \m{e^{B_t^2}}.

	\stopitemize

\stopslide


\startslide [title={Itô integral (\m{∫_0^T X_t^2 \d t < ∞} a.s.)}]

	\startitemize [1]

		\item  Definition: Use sequences of processes in \m{L^2_{\text{ad}} ([0, T] × Ω)} approximating \m{X} in probability to extend the integral \important{in probability}.

		\item  Properties
			\startitemize[3, joinedup]
				\item  Linear
				\item  Mean 0, \bad{but variance? \symbol[fontawesome][meh]}
			\stopitemize

		\item  The associated process: \m{I_t = ∫_0^t X_t \d B_t}
			\startitemize [3, joinedup]
				\item  continuous
				\item  \okay{local} martingale
			\stopitemize

		\item  Example: \m{∫_0^T e^{B_t^2} \d B_t = ∫_0^{B_1} e^{t^2} \d t - ∫_0^T B_t e^{B_t^2} \d t}.

	\stopitemize

\stopslide

\startslide [title={Itô formula}]

	\startitemize [1]

		% \item  A (local, continuous) \important{semimartingale} is a process \m{X_t} that can be written as \m{X_t = X_0 + M_t + A_t}, where
		% \startitemize [n, joinedup]
		% 	\item  \m{M_t} is a mean-zero (local, continuous) martingale, and
		% 	\item  \m{A_t} is an right-continuous adapted process of locally bounded variation.
		% \stopitemize
		% This is equivalently represented in the \important{differential form} as \m{\d X_t = \d M_t + \d A_t}.

		\item  An \important{Itô process} is a process of the form \m{X_t = X_0 + ∫_0^t m(s, X_s) \d s + ∫_0^t σ(s, X_s) \d B_s}, equivalently expressed as \m{\d X_t = m(t, X_t) \d t + σ(t, X_t) \d B_t}.

		[Only makes sense when \m{∫_0^T \brnd[{\abs[m(s, X_s)] + \abs[σ(s, X_s)]^2}] \d s < ∞} a.s.]

	\stopitemize

	\starttheorem[title={\cite[short][Itô1944SI]}]
		Let \m{X_t} be a \m{d}-dimensional Itô process, and let \m{Y_t = f(X_t)}, where \m{f ∈ C^2(ℝ)}. Then \m{f(X_t)} is also a \m{d}-dimensional Itô process, and
			\startformula
				\d f(X_t)  =  \inn[(\D f) (X_t), \d X_t] + \frac12 \inn[\d X_t, (D^2 f)(X_t) \, \d X_t] ,
			\stopformula
			% \startformula
			% 	\d Y_t
			% 	=  \d f(X_t)
			% 	=  ∑_{j = 1}^d  \frac{∂f}{∂x_j} (X_t)  \d A_t^{(j)}
			% 	 + ∑_{j = 1}^d  \frac{∂f}{∂x_j} (X_t) \d M_t^{(j)}
			% 	 + \frac12 ∑_{j, k = 1}^d  \frac{∂^2 f}{∂x_j ∂x_k} (X_t) \d \inn[M^{(j)}, M^{(k)}]_t ,
			% \stopformula
			where we use the rule \important{\m{\d B_t ⊗ \d B_t = I_d \d t}}.
	\stoptheorem

	\startitemize [1]

		\item  Example: For \m{σ} constant, \m{𝓔_t = \exp\brnd[σ B_t - \frac12 σ^2 t]}, we have \m{\d 𝓔_t = \comment{- \frac12 σ^2 𝓔_t \d t} + σ 𝓔_t \d B_t \comment{+ \frac12 σ^2 𝓔_t (\d B_t)^2}}.

	\stopitemize

\stopslide

\startslide [title={Exponential processes and Girsanov theorem}]

	TODO

	Let \m{h ∈ L^2[0, T]}. Then the translated stochastic process \m{W_t = B_t - ∫_0^t h(s) \d s} is a Brownian motion under the probability measure \m{\tilde{ℙ}} defined by the Radon-Nikodym derivative
	\m{\frac{\d \tilde{ℙ}}{\d ℙ} = \exp\brnd[σ B_T - \frac12 σ^2 T] =: 𝓔^{h}_T}.

	Then \m{\tilde{ℙ} ∼ ℙ} and the process \m{Z_t := 𝔼 \brnd[\frac{\d \tilde{ℙ}}{\d ℙ} ∣ 𝓕_t]} is a martingale.

\stopslide

\startslide [title={Stochastic differential equations}]

	\startitemize [1]
		\item  Let \m{ξ ∈ L^2(Ω)} be independent of \m{B_⋅}, and \m{m, σ: [0, T] × ℝ × Ω → ℝ} be \m{𝓑[0, T] × 𝓑(ℝ) × 𝓕} measurable such that \m{m(t, ⋅, ⋅)} and \m{σ(t, ⋅, ⋅)} are \m{𝓑(ℝ) × 𝓕_t} measurable \m{∀ t}.

			Then a \m{𝓕_t}-adapted stochastic process \m{X_t} is called a solution of the stochastic \emph{integral} equation

			\important{\m{X_t = ξ + ∫_0^t m(s, X_s) \d s + ∫_0^t σ(s, X_s) \d B_s}} if for each \m{t}, the \m{X_t} satisfies the integral equation a.s.
		\item  The stochastic differential equation \m{\d X_t = m(t, X_t) \d t + σ(t, X_t) \d B_t, \ X_0 = ξ} is a symbolic representation of the stochastic integral equation.
	\stopitemize

	\starttheorem[title={Existence and uniqueness, Markov property}]
		The stochastic differential equation above has a unique solution if there exists an \m{M > 0} such that the following two conditions are satisfied:
		\startitemize[3, joinedup]
			\item  (Lipschitz condition) \m{\abs[m(t, x) - m(t, y)] + \abs[σ(t, x) - σ(t, y)]^2 ≤ M (1 + \abs[x]^2)} a.s.
			\item  (growth condition) \m{\abs[m(t, x)] + \abs[σ(t, y)]^2 ≤ M (1 + \abs[x]^2)} a.s.
		\stopitemize

		The solution is a Markov process. Moreover if \m{ξ ∈ ℝ}, then the solution is also stationary.
	\stoptheorem

	\startitemize [1, joinedup]
		\item  Example: For \m{σ} constant, the solution of \m{\d 𝓔_t = σ 𝓔_t \d B_t, 𝓔_0 = 1} is given by \m{𝓔_t = \exp\brnd[σ B_t - \frac12 σ^2 t]}.
	\stopitemize

\stopslide

\startslide[title={Multiple Wiener–Itô integrals}]

\stopslide


\stopmode

\stopsection

\page    % Needed for correct color transition

% \startmode [manuscript]

% This is the first part and we are going to talk about generalization of stochastic integrals developed primarily by Professor H.-H. Kuo.

% \stopmode



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Generalization of stochastic calculus %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setupbackgrounds[page][
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-1}]
\startcolor[\getvariable{document}{color-foreground-1}]    % text color

\startsection[title={Generalization of Itô calculus}, reference=sec:generalization-Itô-calculus]

\startmode [presentation]


\startslide [title={Motivation}]

	\startitemize [1]

		\item  Iterated integrals: Consider the iterated integral \m{∫_0^T ∫_0^T \d B_s \d B_t \ugly{= ∫_0^T B_T \d B_t ≟ B_T B_t}}.

		\item  Note that \m{𝔼(B_T B_t) = T ∧ t = \ugly{t ≠ 0}}, so \ugly{no martingale property} \symbol[fontawesome][frown].

		\item  Stochastic differential equations with anticipation
			% \startitemize[3, joinedup]
			% 	\item  \m{\d X_t  =  X_t \d B_t, X_0 = B_1}
			% 	\item  \m{\d Y_t  =  B_T \d B_t, Y_0 = 1}
			% \stopitemize
		\startformula \startalign[m=2, distance=8em, align={right, left, right, left}]
			\NC  \d X_t  \NC =  X_t \d B_t
			\NC  \d Y_t  \NC =  B_T \d B_t
			\NR
			\NC  X_0  \NC =  B_1
			\NC  Y_0  \NC =  1
		\stopalign \stopformula

		\item  Problem: We want to define \m{∫_0^T X_t \d B_t}, where \m{X_⋅} is not adapted (anticipating).

		\item  Some approaches
		\startitemize[3, joinedup]
			\item  Itô's decomposition of integrand \m{B_t = \brnd[B_t - ∫_0^t \frac{B_T - B_s}{T - s} \d s] + ∫_0^t \frac{B_T - B_s}{T - s} \d s}
				% \startformula
				% 	B_t = \brnd[B_t - ∫_0^t \frac{B_T - B_s}{1 - s} \d s] + ∫_0^T \frac{B_T - B_s}{1 - s} \d s
				% \stopformula
			\item  Enlargement of filtration
			\item  White noise theory
			\item  …

				% \m{B_t = \brnd[B_t - ∫_0^t \frac{B_T - B_s}{1 - s} \d s] + ∫_0^T \frac{B_T - B_s}{1 - s} \d s}
		\stopitemize

	\stopitemize

\stopslide


\startslide [title={The new integral \cite[short][AyedKuo2008, AyedKuo2010]}: Idea]

	\startitemize[1]

		\item  A process \m{Y^⋅} and filtration \m{ℱ_⋅} are called \important{instantly independent} if \m{Y^t} and \m{ℱ_t} are independent \m{∀ t}.

		\item  Ideas
			\startitemize[n, joinedup]

				\item  Decompose the integrand into \good{adapted} and \okay{instantly independent} parts.

				\item  Evaluate the \good{adapted} and the \okay{instantly independent} parts at the \good{left} and \okay{right} endpoints.

			\stopitemize

		\item  Consider two continuous stochastic processes, \good{\m{X_t} adapted} and \okay{\m{Y^t} instantly independent} w.r.t. \m{ℱ_⋅}. Then the integral \m{∫_0^T \good{X_t} \okay{Y^t} \d B_t} is \important{defined} as
			\startformula
				∫_0^T \good{X_t} \okay{Y^t} \d B_t  ≜  \lim_{\norm[Δ_n] → 0}  ∑_{j = 0}^{n - 1} \good{X_{t_{j}}} \okay{Y^{t_{j+1}}} ΔB_j ,
			\stopformula
			provided that the limit exists in probability.

		\item  Now, for any stochastic process \m{Z(t) = ∑_{k = 1}^n \good{X_t^{(k)}} \okay{Y^t_{(k)}}} we extend the definition by linearity.

		\item  This is well-defined \cite[short][HwangKuoSaitôZhai2016].
		%\m{∫_0^T Z(t) \d B_t = ∑_{k = 1}^n ∫_0^T Z(t) X_t^{(k)} Y^t_{(k)} \d B_t}.
		% \startformula
		% 	∫_0^T Z(t) \d B_t = ∑_{k = 1}^n ∫_0^T \good{X_t^{(k)}} \okay{Y^t_{(k)}} \d B_t
		% \stopformula

	\stopitemize

\stopslide

\startslide[title={A simple example}]

	\startitemize [1]

		\item  	In the following, denote \m{Δ B_j = B_{t_{j+1}} - B_{t_j}} and \m{\lim} is the limit in \m{L^2}.
			\startformula \startalign
				\NC  ∫_0^t B_T \d B_t
					\NC =  ∫_0^t (\good{B_t} + \okay{(B_T - B_t)}) \d B_t
					    =  \good{∫_0^t B_t \d B_t}  +  \okay{∫_0^t (B_T - B_t) \d B_t}
				\NR \NC
					\NC =  \good{\lim ∑_{j = 0}^{n - 1} B_{t_j} Δ B_j}
						+  \okay{\lim ∑_{j = 0}^{n - 1} (B_T - B_{t_{j + 1}}) Δ B_j}
				\NR \NC
					\NC =  \lim ∑_{j = 0}^{n - 1} \brnd[B_T - Δ B_j] Δ B_j
				\NR \NC
					\NC =  B_T \lim ∑_{j = 0}^{n - 1} Δ B_j - \lim ∑_{j = 0}^{n - 1} (Δ B_j)^2
					    =  B_T B_t - t
			\stopalign \stopformula

		\item  Note that \m{𝔼(B_T B_t - t) = 0}.

		\item  In general, \m{𝔼 ∫_0^t Z(t) \d B_t = 0}. \good{\symbol[fontawesome][smile]}
	\stopitemize

\stopslide

\startslide [title={Generalized Itô formula \cite[short][HwangKuoSaitôZhai2016]}]

	\startitemize [1]

		\item  Let \m{\d X_t = m(t) \d t + σ(t) \d B_t} be an \m{d}-dimensional \good{Itô} process, \m{Y^t = \tilde{m}(t) \d t + \tilde{σ}(t) \d B_t} be a \m{\tilde{d}}-dimensional \okay{instantly independent} process, \m{f(x, y) ∈ C^2(ℝ^2)}. Then
			\startformula \startalign
					\NC \d f(X_t, Y^t)  =
					\NC \good{\inn[(\D_x f) (X_t, Y^t), \d X_t]
						+ \frac12 \inn[\d X_t, (D_x^2 f)(X_t, Y^t) \, \d X_t]}
				\NR \NC
					\NC + \okay{\inn[(\D_y f) (X_t, Y^t), \d Y^t]
						- \frac12 \inn[\d Y^t, (D_y^2 f)(X_t, Y^t) \, \d Y^t]} ,
			\stopalign \stopformula
			where we use the rule \important{\m{\d B_t ⊗ \d B_t = I_d \d t}}.

		\item  Example: TODO

	\stopitemize

\stopslide

\startslide[title={Iterated integrals}]

	\starttheorem[title={\cite[short][Itô1951MWI]}]
		Let \m{f ∈ L^2([0, T]^n)} and \m{\hat{f}} be its symmetrization. Then
		\startformula
			∫_{[0, T]^n} f(t_1, …, t_n) \d B_{t_1} … \d B_{t_n}  =  \bad{n!} ∫_0^T ⋯ ∫_0^{\bad{t_{n-1}}} \bad{\hat{f}}(t_1, …, t_n) \d B_{t_n} … \d B_{t_1} ,
		\stopformula
	\stoptheorem

	\starttheorem[title={\cite[short][AyedKuo2010]}]
		Let \m{f ∈ L^2([0, T]^n)}. Then
		\startformula
			∫_{[0, T]^n} f(t_1, …, t_n) \d B_{t_1} … \d B_{t_n}  =  ∫_0^T ⋯ ∫_0^T f(t_1, …, t_n) \d B_{t_n} … \d B_{t_1} .
		\stopformula
	\stoptheorem

\stopslide

\startslide [title={Near-martingale property \cite[short][HwangKuoSaitôZhai2017]}]

	\startitemize [1]

		\item  Question: What are the analogues of the martingale property and the Markov property?

		\item  Partial answer: near-martingales

		\item  Let \m{Z(t)} be a stochastic process such that \m{𝔼\abs[Z(t)] < ∞ \ ∀ t}, and \m{0 ≤ s ≤ t ≤ T}. Then, with respect to \m{ℱ_⋅}, the process \m{Z(t)} is called a
			\startitemize[3, joinedup]
				\item  \important{near-martingale} if \m{𝔼(Z(t) - Z(s) ∣ ℱ_s) = 0},
				\item  \important{near-submartingale} if \m{𝔼(Z(t) - Z(s) ∣ ℱ_s) ≥ 0}, and
				\item  \important{near-supermartingale} if \m{𝔼(Z(t) - Z(s) ∣ ℱ_s) ≤ 0}.
			\stopitemize

	\stopitemize

\stopslide

\stopmode

\stopsection

\page    % Needed for correct color transition



%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Large deviations theory %
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setupbackgrounds[page][
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-2}]
\startcolor[\getvariable{document}{color-foreground-2}]    % text color

\startsection[title={Large deviations theory}, reference=sec:large-deviations-theory]


\startmode [presentation]

\startslide [title={Motivation: an example}]

	\startitemize [n]
		\item  Setup. Let the following hold:
			\startitemize[1, joinedup]
				\item  \m{(Ω, ℱ, ℙ)} is a probability space.
				\item  \m{(X_n)} is a sequence of i.i.d. random variables on \m{(Ω, ℱ, ℙ)} with finite moment generating function \m{M}.
				\item  \m{𝔼 X_1 = m}, \m{𝕍 X_1 = σ^2}, and \m{X_1 ∼ μ}.
				\item  \m{\bar{X}_n = \frac1n ∑_{j = 1}^n X_j}.
			\stopitemize

		\item  Asymptotic behavior of \m{\bar{X}_n}:
			\startitemize[1, joinedup]
				\item  Weak law of large numbers: \m{\bar{X}_n \xrightarrow{ℙ} m}.
				\item  Central limit theorem: \m{\sqrt{n} \bar{X}_n \xrightarrow{w^*} \sqrt{n} m + 𝓝(0, σ^2)}.
			\stopitemize

		\item  But at what speed?

		\item  We want to \emph{control large deviations from the mean}.

		% \item  \m{≍}

	\stopitemize

\stopslide

\startslide [title={Example: large deviation bounds}]

	\startitemize [n]
		\item  Fixing \m{x > m} and forcing the exponential with a free parameter \m{θ > 0}, we get
			\startformula
				ℙ\bcrl[\bar{X}_n ≥ x]
				=  ℙ\bcrl[e^{θn\bar{X}_n} ≥ e^{θnx}]
				≤  e^{-θnx} 𝔼\brnd[e^{θn\bar{X}_n}]
				=  e^{-θnx} M_{X}(θ)^n
				=  e^{-n(θx - \log M_{X}(θ))}
			\stopformula

		\item  Since \m{θ} was arbitrary, we have
			\startformula
				ℙ\bcrl[\bar{X}_n ≥ x]
				≤  \inf_θ e^{-n(θx - \log M_{X}(θ))}
				=  e^{-n \sup_θ (θx - \log M_{X}(θ))}
				=: e^{-n I(x)} .
			\stopformula

		\item  Generalizing, we get the \important{large deviation upper bound}
			\startformula
				\limsupm \frac1n \log ℙ\bcrl[\bar{X}_n ∈ E]  ≤  -\inf_{\clsr[E]} I  \qquad  ∀ E ∈ 𝓑 .
			\stopformula

		\item  We can also obtain a lower bound too using an exponential change of measure
			\startformula
				\liminfm \frac1n \log ℙ\bcrl[\bar{X}_n ∈ E]  ≥  -\inf_{\intr[E]} I  \qquad  ∀ E ∈ 𝓑 .
			\stopformula

		\item  So informally, we get \m{ℙ\bcrl[\bar{X}_n = x] ≍ e^{-n I(x)}} for \m{x ∈ ℝ}.

	\stopitemize

\stopslide

\startslide [title={Definitions}]

	\startitemize [1]

		\item  The setup: \m{(X_n)} is a stochastic process on \m{(Ω, ℱ, ℙ)} taking values in a Polish space \m{(𝓧, d)}.

		\item  A function \m{I: 𝓧 → [0, ∞]} is called a \important{rate function} if it has compact level sets.

		\item  \m{I} is lower semicontinuous and attains its infimum on a nonempty closed set.

		\item  For any Borel set \m{E}, denote \m{I(E) = \inf_{x ∈ E} I(x)}.

	\stopitemize

	\startdefinition
		\m{(X_n)} is said to satisfy the \important{large deviation principle on \m{𝓧} with rate function \m{I}} if the following two conditions hold.
		\startformula \startalign[n=4]
			\NC  \text{(upper bound)}  \qquad  \NC  \limsupm \frac1n \log ℙ\bcrl[\bar{X}_n ∈ F]  \NC ≤  -I(F)  \NC  \qquad  ∀ F \text{ closed}  \NR
			\NC  \text{(lower bound)}  \qquad  \NC  \liminfm \frac1n \log ℙ\bcrl[\bar{X}_n ∈ E]  \NC ≥  -I(G)  \NC  \qquad  ∀ G \text{ open}
		\stopalign \stopformula
	\stopdefinition

\stopslide

\startslide [title={Cramér theorem}]

	\starttheorem [title={\cite[short][Cramér1938]}]
		Let \m{(X_n)} be a sequence of i.i.d. real random variables with finite moment generating function \m{M}. Then \m{(X_n)} follows large deviation principle with rate function \m{I(x) = \sup_θ \brnd[θ x - \log M(θ)]}.
	\stoptheorem

	Rate function for some common distributions for \m{X_⋅}
	\placetable[force,none]{}{%    % This centers the table
	\starttabulate[|M|M|M|]
		\FL
		\NC  \text{Distribution}  \NC  M(θ)  \NC  I(x)  \NR
		\FL
		\NC  Bern(p)  \NC  1 - p + p e^θ  \NC  x \log \frac{x}{1 - p} + (x - 1) \log \frac{p}{x - 1}  \NR
		\NC  Pois(λ)  \NC  e^{λ(e^θ - 1)}  \NC  λ - x + x \log \frac{x}{λ}  \NR
		\NC  Exp(λ)   \NC  \inv[(1 - θ \inv[λ])]  \NC  λx - 1 + x \log(λ x)  \NR
		\NC  𝓝(m, σ^2)  \NC  e^{m θ + \frac12 σ^2 θ^2}  \NC  \frac{(x - m)^2}{2 σ^2}  \NR
		\NC  χ^2(k)  \NC  (1 - 2 θ)^{-\frac{k}{2}}  \NC  \frac12 \brnd[x - k + k \log\frac{k}{x}]    \NR
		\BL
	\stoptabulate}
	% ToDo: Add more.
	% ToDo: Add the computation in the appendix.

\stopslide

\startslide [title={Sanov theorem}]

\stopslide

\startslide [title={LD in ∞-dimensions --- Schilder theorem}]

	\bold{Aim}: Estimate the probability that a scaled-down sample path of a Brownian motion will stray far from the mean path (the \m{0} function).

	\bold{Setup}
	\startitemize [1, joinedup]
		\item  Let \m{B_⋅} be a \m{d}-dimensional Brownian motion, so \m{B_⋅ ∈ C_0 = C_0([0, T]; ℝ^d)}
		\item  \m{∀ ε > 0}, let \m{W_ε} denote the law of \m{\sqrt{ε} B_⋅}
		\item  Let \m{\text{CM} = \bcrl[ω ∈ C_0 : ω ∈ \text{AC}, \text{ and } \dot{ω}_t ∈ L^2[0, T]]}
	\stopitemize

	\starttheorem %[title={\cite[short][Schilder1966]}]
		On the Banach space \m{\brnd[C_0, {\norm[⋅]}_∞]}, the family of probability measures \m{\bcrl[W_ε : ε > 0]} satisfy the large deviations principle with the rate function \m{I : C_0 → \clsr[ℝ]} given by
		\startformula
			I(ω)  =  \brnd[\frac12 ∫_0^T {\abs[\dot{ω}(t)]}^2 \d t] 𝟙_{\text{AC}}(ω) + ∞ 𝟙_{\text{AC}^∁}(ω)
		\stopformula
	\stoptheorem

\stopslide

\startslide [title={Freidlin–Wentzell theorem}]

	\bold{Aim}: Estimate the probability that a scaled-down sample path of an Itô diffusion will stray far from the mean path.

	% Generalizes the Schilder theorem for Itô diffusions.

	\bold{Setup}
	\startitemize [1, joinedup]
		\item  Let \m{B_⋅} be a \m{d}-dimensional Brownian motion, so \m{B_⋅ ∈ C_0 = C_0([0, T]; ℝ^d)}
		\item  \m{∀ ε > 0}, let \m{X^{(ε)}} be a \m{ℝ^d}-valued Itô diffusion solving an Itô SDE of the form
			\startformula
				\d X^{(ε)}_t = b(X^{(ε)}_t) \d t + \sigma(X^{(ε)}_t) \sqrt{ε} \d B_t , \quad X^{(ε)}_0 = 0 .
			\stopformula
		\item  \m{∀ ε > 0}, let \m{W_ε} denote the law of \m{X^{(ε)}_⋅}.
	\stopitemize

	\starttheorem [title={Freidlin, Wentzell (year?)}]
		On the Banach space \m{\brnd[C_0, {\norm[⋅]}_∞]}, the family of probability measures \m{\bcrl[W_ε : ε > 0]} satisfy the large deviations principle with the rate function \m{I : C_0 → \clsr[ℝ]} given by
		\startformula
			I(ω)  =  \brnd[\frac12 ∫_0^T {\abs[\dot{ω}_t - b(ω_t)]}^2 \d t] 𝟙_{H^1([0, T]; ℝ^d)}(ω) + ∞ 𝟙_{H^1([0, T]; ℝ^d)^∁}(ω)
		\stopformula
	\stoptheorem

\stopslide

\stopmode

\stopsection



%%%%%%%%%%%%%%
% Conclusion %
%%%%%%%%%%%%%%

\setupbackgrounds[page][
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-0}]
\startcolor[\getvariable{document}{color-foreground-0}]    % text color

\startsection[title={Conclusion}, reference=sec:conclusion]


\startmode [presentation]

\startslide [title={Open areas for research}]
	\startitemize[3]
		\item  Extension to SDEs with anticipating coefficients
		\item  Near-Markov property
		\item  Girsanov theorem for anticipating integrals
		\item  Freidlin-Wintzell type result for SDEs with anticipation
	\stopitemize

	\framed [width=local, height=8em, autowidth=force] {    % wiki/Framed
		\input ward
	}
\stopslide

\stopmode

\stopsection



%%%%%%%%%%%%%%%%%
% Sample Slides %
%%%%%%%%%%%%%%%%%

\setupbackgrounds[page][
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-0}]
\startcolor[\getvariable{document}{color-foreground-0}]    % text color

\startsection[title={Sample slides}, reference=sec:sample-slides]

\startmode [presentation]

\startslide [title={Possible areas of interest}]
	\startitemize[3]
		\item  Extension to SDEs with anticipating coefficients
		\item  Near-Markov property
		\item  Girsanov theorem for generalized integration
		\item  Freidlin-Wintzell type result for SDEs with anticipating initial conditions
	\stopitemize

	\framed [width=local, height=8em, autowidth=force] {    % wiki/Framed
		\starttheorem[title={Cramér, 1938}]
			Let \m{X_{1}, X_{2}, \dots}be a series of i.i.d. real random variables with finite logarithmic moment generating function, for example \m{Λ(t) < ∞ \, ∀ t ∈ ℝ}.

			Then the Legendre transform of \m{Λ}, \m{Λ^* = \sup_{t ∈ ℝ} (t x - Λ(t))} satisfies
			\startformula
				\lim_{n → ∞}  \frac{1}{n}  \log ℙ{\brnd[∑_{i=1}^n X_i ≥ n x]}  =  - Λ^*(x)  \quad  ∀ x > 𝔼(X_1)
			\stopformula
		\stoptheorem
	}
\stopslide

\startslide [title={Freidlin–Wentzell theorem}]

	\startcolumns [n=2]
	{\tfb Column 1}

		\input ward

	\column

	{\tfb Itô table}

		\starttabulate[|M|M|M|]
			\HL
			\NC  ×  \NC  \d t  \NC  \good{\d B_t}  \NR
			\HL
			\NC  \d t  \NC  0  \NC  0  \NR
			\NC  \good{\d B_t}  \NC  0  \NC  \good{\d t}  \NR
			\HL
		\stoptabulate

	\stopcolumns

	% \startitemize[8,columns,two]
	% 	\item One
	% 	\item Two
	% 	\item Three
	% \stopitemize

\stopslide

\startslide[title={Something}]

	\startitemize[8, columns, two]
		\item One
		\item Two
		\item Three
		\item Four
	\stopitemize

\stopslide


\stopmode

\stopsection

\stopbodymatter




%%%%%%%%%%%%%%%
% Back matter %
%%%%%%%%%%%%%%%

\startbackmatter
\startmode [presentation]
\startslide [title={Bibliography}]
	\placelistofpublications
\stopslide
\stopmode
\stopbackmatter

\stoptext
