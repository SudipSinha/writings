\environment env-talks

% lsu-math-301d

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is where the document starts.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\starttext

\startfrontmatter

%%%%%%%%%%%%%%%%
% Front matter %
%%%%%%%%%%%%%%%%

\setupbackgrounds [page] [
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-0}]
\startcolor [\getvariable{document}{color-foreground-0}]    % text color


% \startmode [handout]
% \startcolumns
% \stopmode


% Introduction
\startcolor [\getvariable{document}{color-foreground-0}]    % text color

\startmode [presentation]

\startslide

\startalign [middle]

	{\tfd
		\color[\getvariable{document}{color-foreground-1}]{A generalization of ItÃ´ calculus}\\
		and\\
		\color[\getvariable{document}{color-foreground-2}]{large deviations theory}}

	\blank[2*line]

	{\tfb \getvariable{document}{author}}

	\blank[line]

	{\tfa \getvariable{document}{date}}

	\blank[2*line]

	Advisors

	\color[\getvariable{document}{color-foreground-1}]{Prof Hui-Hsiung Kuo}

	\color[\getvariable{document}{color-foreground-2}]{Prof Padmanabhan Sundar}
\stopalign
\stopslide


% Table of contents
\startslide [title={Outline}]
	\placecontent

\stopslide
\stopmode

% \startmode [manuscript]

% This presentation is going to be on two topics:
% \startitemize[n,nowhite,after]
% 	\item  Generalization of stochastic integrals developed primarily by Professor H.-H. Kuo
% 	\item  Applications of generalization in large deviations theory
% \stopitemize

% \stopmode

\stopfrontmatter



\startbodymatter

%%%%%%%%%%%%%%%%
% Introduction %
%%%%%%%%%%%%%%%%

\setupbackgrounds [page] [
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-0}]
\startcolor [\getvariable{document}{color-foreground-0}]    % text color

\startsection [title={Introduction and motivation}, reference=sec:introduction]

\startmode [presentation]

\startslide [title={Quick revision and notations}]

	\startitemize [4]

		\item  Let \m{T âˆˆ (0, âˆ)}, and denote \m{[0, T]} as the index set for \m{t}.

		\item  Let \m{(Î©, â„±, â„±_{\argdotsub}, â„™)} be a filtered probability space.

		\item  \m{B_{\argdotsub}} is a Brownian motion on \m{(Î©, â„±, â„±_{\argdotsub}, â„™)}.

		\item  Properties of \m{B_{\argdotsub}}
			\startitemize [5, columns, joinedup]
				\item  starts at 0
				\item  has independent increments
				\item  \m{B_t - B_s âˆ¼ ğ“(0, t - s)}
				\item  continuous paths
				\item  has \bad{unbounded linear variation \frown}
				\item  has \good{bounded quadratic variation \smile}
				\item  \m{ğ”¼(B_t B_s) = s âˆ§ t}
				\item  martingale
			\stopitemize

		\item  \bad{Naive integration w.r.t. \m{B_t}: not possible}.

		\item  A stochastic process \m{X_{\argdotsub}} is called adapted to \m{â„±_{\argdotsub}} if \m{X_t} is measurable w.r.t. \m{â„±_t} \m{âˆ€t}.

	\stopitemize
\stopslide

\startslide [title={Wiener integral for \m{f âˆˆ L^2[0, T]}}]

	\startitemize [4]

		\item  Definition of the integral:
			\startitemize [n, joinedup]
				\item  Step functions \m{f = âˆ‘_{j = 0}^{n-1} c_j ğŸ™_{[t_j, t_{j + 1})}(t)}: Define \m{âˆ«_0^T f(t) \d B_t  =  âˆ‘_{j = 0}^{n-1} c_j Î” B_j}, where

					\important{\m{Î” B_j = B_{t_{j + 1}} - B_{t_j}}}.

				\item  \m{f âˆˆ L^2[0, T]}: Use step functions approximating \m{f} to extend the integral \important{a.s.}
			\stopitemize

		\item  Properties of the integral:
			\startitemize [5, joinedup]
				\item  Linear.
				\item  \good{Gaussian distribution} with mean 0 and variance \m{\norm[f]_{L^2[0, T]}^2} (ItÃ´ isometry).
				\item  Corresponds to the Riemannâ€“Stieltjes integral for continuous functions of bounded variation.
			\stopitemize

		\item  Properties of the associated process \m{I_{\argdotsub} = âˆ«_0^{\argdotsup} f(t) \d B_t}:
			\startitemize [5, joinedup]
				\item  continuity
				\item  martingale
			\stopitemize

		\item  Problem: Cannot integrate stochastic processes.

	\stopitemize
\stopslide

\startslide [title={Trying to integrate stochastic processes}]

	\startitemize [4]

		\item  \m{âˆ«_0^T B_t \d B_t â‰Ÿ}

			Since \m{B_t} is continuous, let us try Riemannâ€“Stieltjes integral. Consider a sequence of partitions \m{Î”_n} such that \m{\norm[Î”_n] â†’ 0}. Then
			\startformula
				âˆ«_0^T B_t \d B_t  =  \lim âˆ‘_{j = 0}^{n - 1} B_{t_j^*} Î” B_j .
			\stopformula

		\item  Choosing different endpoints for \m{t_j^*} gives us different results.
			\starttabulate [|c|m|c|m|c|c|]
				\NC  \m{t_j^*}  \NC  âˆ«_0^t B_s \d B_s  \NC  Intuitive?  \NC  ğ”¼  \NC  Martingale?  \NC  Theory  \NR
				\FL
				\NC  \good{left}   \NC  \good{\frac12 \brnd[B_t^2 - t]}  \NC  \good{\frown}  \NC  \good{0}  \NC  \good{\smile}  \NC  \good{ItÃ´}  \NR
				\NC  mid    \NC  \frac12 \brnd[B_t^2]  \NC  \smile  \NC  \frac12 t  \NC  \frown  \NC  Stratonovich  \NR
				\NC  \bad{right}  \NC  \bad{\frac12 \brnd[B_t^2 + t]}  \NC  \bad{\frown}  \NC  \bad{t}  \NC  \bad{\frown}  \NC    \NR
				\BL
			\stoptabulate

		\item  Which one do we choose?

	\stopitemize
\stopslide

\startslide [title={ItÃ´ integral for \m{X_{\argdotsub} âˆˆ L^2_{\text{ad}} ([0, T] Ã— Î©)}}]

	\startitemize [4]

		\item  Definition of the integral:
			\startitemize [n, joinedup]
				\item  Adapted step processes \m{X_t(Ï‰) = âˆ‘_{j = 0}^{n-1} Î¾_j(Ï‰) ğŸ™_{[t_j, t_{j + 1})}(t)}: define \m{âˆ«_0^T X_t \d B_t  =  âˆ‘_{j = 0}^{n-1} Î¾_j Î” B_j}.
				\item  \m{X âˆˆ L^2_{\text{ad}} ([0, T] Ã— Î©)}: use step processes approximating \m{X} to extend the integral \important{in \m{L^2(Î©)}}.
			\stopitemize

		\item  Properties of the integral:
			\startitemize [5, joinedup]
				\item  Linear.
				\item  Mean 0 and variance \m{\norm[f]_{L^2[0, T]}^2} \good{(ItÃ´ isometry)}.
				\item  For \m{X_{\argdotsub}} continuous,
					\m{âˆ«_0^T X_t \d B_t
						=  \lim âˆ«_0^T X_{\floor[\frac{t n}{n}]} \d B_t
						=  \lim âˆ‘_{j = 0}^{n - 1} X_{t_j} Î” B_j}.
			\stopitemize

		\item  Properties of the associated process \m{I_{\argdotsub} = âˆ«_0^{\argdotsup} X_t \d B_t}:
			\startitemize [5, joinedup]
				\item  continuity
				\item  martingale
			\stopitemize

		\item  Example: \m{âˆ«_0^t B_s \d B_s = \frac12 (B_t^2 - t) \quad âˆ€ t}.

		% \item  Problem: Cannot integrate many continuous functions of \m{B_t}, for example \m{e^{B_t^2}}.

	\stopitemize
\stopslide

\startslide [title={ItÃ´ integral for \m{X_{\argdotsub}} such that \m{âˆ«_0^T X_t^2 \d t < âˆ} a.s.}]

	\startitemize [4]

		\item  Definition: Use sequences of processes in \m{L^2_{\text{ad}} ([0, T] Ã— Î©)} approximating \m{X} in probability to extend the integral \important{in probability}.

		\item  Properties of the integral:
			\startitemize [5, joinedup]
				\item  Linear.
				\item  \bad{Mean and variance? \frown}
			\stopitemize

		\item  Properties of the associated process \m{I_{\argdotsub} = âˆ«_0^{\argdotsup} X_t \d B_t}:
			\startitemize [5, joinedup]
				\item  continuity
				\item  \okay{local} martingale
			\stopitemize

		\item  Example: \m{âˆ«_0^T e^{B_t^2} \d B_t = âˆ«_0^{B_1} e^{t^2} \d t - âˆ«_0^T B_t e^{B_t^2} \d t}.

	\stopitemize
\stopslide

\startslide [title={The ItÃ´ formula}]

	\startitemize [4]

		% \item  A (local, continuous) \important{semimartingale} is a process \m{X_t} that can be written as \m{X_t = X_0 + M_t + A_t}, where
		% \startitemize [n, joinedup]
		% 	\item  \m{M_t} is a mean-zero (local, continuous) martingale, and
		% 	\item  \m{A_t} is an right-continuous adapted process of locally bounded variation.
		% \stopitemize
		% This is equivalently represented in the \important{differential form} as \m{\d X_t = \d M_t + \d A_t}.

		\item  An \important{ItÃ´ process} is a process of the form \m{X_t = X_0 + âˆ«_0^t m_s \d s + âˆ«_0^t Ïƒ_s \d B_s}.

		Equivalently expressed as \m{\d X_t = m_t \d t + Ïƒ_t \d B_t}.

		% [Only makes sense when \m{âˆ«_0^T \brnd[{\abs[m_s] + \abs[Ïƒ_s]^2}] \d s < âˆ} a.s.]

	\stopitemize

	\starttheorem[title={\cite[short][ItÃ´1944SI]}]
		Let \m{X_t} be a \m{d}-dimensional ItÃ´ process, and let \m{Y_t = f(X_t)}, where \m{f âˆˆ C^2(â„)}. Then \m{f(X_t)} is also a \m{d}-dimensional ItÃ´ process, and
			\startformula
				\d f(X_t)  =  \inn[(\D f) (X_t), \d X_t] + \frac12 \inn[\d X_t, (D^2 f)(X_t) \, \d X_t] ,
			\stopformula
			% \startformula
			% 	\d Y_t
			% 	=  \d f(X_t)
			% 	=  âˆ‘_{j = 1}^d  \frac{âˆ‚f}{âˆ‚x_j} (X_t)  \d A_t^{(j)}
			% 	 + âˆ‘_{j = 1}^d  \frac{âˆ‚f}{âˆ‚x_j} (X_t) \d M_t^{(j)}
			% 	 + \frac12 âˆ‘_{j, k = 1}^d  \frac{âˆ‚^2 f}{âˆ‚x_j âˆ‚x_k} (X_t) \d \inn[M^{(j)}, M^{(k)}]_t ,
			% \stopformula
			where we use the rule \important{\m{\d B_t âŠ— \d B_t = I_d \d t}}.
	\stoptheorem

	\startitemize [4]

		\item  Example: For \m{Ïƒ} constant, \m{ğ“”_t = \exp\brnd[Ïƒ B_t - \frac12 Ïƒ^2 t]}, \m{\d ğ“”_t = \comment{- \frac12 Ïƒ^2 ğ“”_t \d t} + Ïƒ ğ“”_t \d B_t \comment{+ \frac12 Ïƒ^2 ğ“”_t (\d B_t)^2}}.

	\stopitemize
\stopslide

\startslide [title={Exponential processes and the Girsanov theorem}]

	\startitemize [4]

		\item  Let \m{h_{\argdotsub}} be a stochastic process. The \important{associated exponential process} is defined as
			\startformula
				ğ“”^{(h)}_t = \exp\brnd[âˆ«_0^t h_s \d B_s - \frac12 âˆ«_0^t h_s^2 \d s] .
			\stopformula

		\item  The exponential process is a martingale if and only if \m{ğ”¼ ğ“”^{(h)}_t = 1 \ âˆ€ t}.

		\item  (\important{Novikov condition})  The exponential process is a martingale if \m{ğ”¼ \exp\brnd[\frac12 âˆ«_0^T h_t^2 \d t] < âˆ}.

		\item  (\important{Girsanov theorem})
			The translated stochastic process \m{W_t = B_t - âˆ«_0^t h(s) \d s} is a Brownian motion under the probability measure \m{\tilde{â„™}} defined by the Radon-Nikodym derivative
			\m{\frac{\d \tilde{â„™}}{\d â„™} = ğ“”^{(h)}_T}.

			% Moreover the process \m{Z_t := ğ”¼ \brnd[ğ“”^{h}_T âˆ£ ğ“•_t]} is a martingale.

	\stopitemize
\stopslide

\startslide [title={Stochastic differential equations}]

	\startitemize [4]

		\item  Let \m{Î¾ âˆˆ L^2(Î©)} be independent of \m{B_{\argdotsub}}, and \m{m, Ïƒ: [0, T] Ã— â„ Ã— Î© â†’ â„} be \m{ğ“‘[0, T] Ã— ğ“‘(â„) Ã— ğ“•} measurable such that \m{m(t, â‹…, â‹…)} and \m{Ïƒ(t, â‹…, â‹…)} are \m{ğ“‘(â„) Ã— ğ“•_t} measurable \m{âˆ€ t}.

			Then a \m{ğ“•_t}-adapted stochastic process \m{X_t} is called a solution of the \important{stochastic \emph{integral} equation} \important{\m{X_t = Î¾ + âˆ«_0^t m(s, X_s) \d s + âˆ«_0^t Ïƒ(s, X_s) \d B_s}} if for each \m{t}, the \m{X_t} satisfies the integral equation a.s.

		\item  The \important{stochastic \emph{differential} equation} \m{\d X_t = m(t, X_t) \d t + Ïƒ(t, X_t) \d B_t, \ X_0 = Î¾} is a \emph{symbolic representation} of the stochastic integral equation.
	\stopitemize

	\starttheorem [title={Existence and uniqueness, Markov property}]

		The stochastic differential equation above has a unique solution if there exists an \m{M > 0} such that the following two conditions are satisfied:
		\startitemize [5, joinedup]
			\item  (Lipschitz condition) \m{\abs[m(t, x) - m(t, y)]^2 + \abs[Ïƒ(t, x) - Ïƒ(t, y)]^2 â‰¤ M \abs[x - y]^2} a.s.
			\item  (growth condition) \m{\abs[m(t, x)]^2 + \abs[Ïƒ(t, y)]^2 â‰¤ M \brnd[1 + {\abs[x]}^2]} a.s.
		\stopitemize

		The solution is a Markov process.

		Moreover if \m{Î¾ âˆˆ â„} and \m{m, Ïƒ} are function of only \m{x}, then the solution is also stationary.

	\stoptheorem

	\startitemize [1, joinedup]

		\item  	Example: For \m{Ïƒ} constant, \m{\d ğ“”_t = Ïƒ ğ“”_t \d B_t, ğ“”_0 = 1} is solved by \m{ğ“”_t = \exp\brnd[Ïƒ B_t - \frac12 Ïƒ^2 t]}.

	\stopitemize
\stopslide

\startslide [title={Multiple Wienerâ€“ItÃ´ integrals}]

	\startitemize [4]

		\item  How do we define the double integral?

		\item  Naive idea: \m{âˆ«_0^t âˆ«_0^t \d B_u \d B_v = âˆ«_0^t \d B_u âˆ«_0^t \d B_v = B_t^2}.

			But \m{ğ”¼ B_t^2 = \ugly{t â‰  0}}, so \ugly{no martingale property}. \frown

		\item  ItÃ´'s idea: remove the diagonal to get \m{âˆ«_0^t âˆ«_0^t \d B_u \d B_v  =  2 âˆ«_0^t âˆ«_0^v \d B_u \d B_v  =  B_t^2 - t}. \smile

	\stopitemize

	\starttheorem[title={\cite[short][ItÃ´1951MWI]}]
		Let \m{f âˆˆ L^2([0, T]^n)} and \m{\bad{\hat{f}}} be its symmetrization. Then
		\startformula
			âˆ«_{[0, T]^n} f(t_1, â€¦, t_n) \d B_{t_1} â‹¯ \d B_{t_n}  =  \bad{n!} âˆ«_0^T â‹¯ âˆ«_0^{\bad{t_{n-2}}} \brnd[âˆ«_0^{\bad{t_{n-1}}} \bad{\hat{f}}(t_1, â€¦, t_n) \d B_{t_n}] \d B_{t_{n-1}} â‹¯ \d B_{t_1} .
		\stopformula
		% \m{\hat{f}(t_1, â€¦, t_n)  =  \frac{1}{n!} âˆ‘_{Ïƒ âˆˆ S_n} f(t_{Ïƒ(1)}, â€¦, t_{Ïƒ(n)})}
	\stoptheorem

	% \startitemize [4]
	% 	\item  Example: \m{}
	% \stopitemize
\stopslide


\stopmode

\stopsection

\page    % Needed for correct color transition

% \startmode [manuscript]

% This is the first part and we are going to talk about generalization of stochastic integrals developed primarily by Professor H.-H. Kuo.

% \stopmode



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Generalization of stochastic calculus %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setupbackgrounds [page] [
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-1}]
\startcolor  [\getvariable{document}{color-foreground-1}]    % text color

\startsection [title={Generalization of ItÃ´ calculus}, reference=sec:generalization-ItÃ´-calculus]

\startmode [presentation]

\startslide [title={Motivation}]

	\startitemize [4]

		\item  Iterated integrals: Consider the iterated integral \m{âˆ«_0^T âˆ«_0^T \d B_s \d B_t \ugly{= âˆ«_0^T B_T \d B_t â‰Ÿ B_T B_t}}.

		\item  Note that \m{ğ”¼(B_T B_t) = T âˆ§ t = \ugly{t â‰  0}}, so \ugly{no martingale property} \frown.

		\item  Stochastic differential equations with anticipation:
			% \startitemize [5, joinedup]
			% 	\item  \m{\d X_t  =  X_t \d B_t, X_0 = B_1}
			% 	\item  \m{\d Y_t  =  B_T \d B_t, Y_0 = 1}
			% \stopitemize
		\startformula \startalign[m=2, distance=8em, align={right, left, right, left}]
			\NC  \d X_t  \NC =  X_t \d B_t
			\NC  \d Y_t  \NC =  B_T \d B_t
			\NR
			\NC  X_0  \NC =  B_1
			\NC  Y_0  \NC =  1
		\stopalign \stopformula

		\item  Problem: We want to define \m{âˆ«_0^T X_t \d B_t}, where \m{X_{\argdotsub}} is not adapted (anticipating).

		\item  Some approaches:
		\startitemize [5, joinedup]
			\item  ItÃ´'s decomposition of integrand \m{B_t = \brnd[B_t - âˆ«_0^t \frac{B_T - B_s}{T - s} \d s] + âˆ«_0^t \frac{B_T - B_s}{T - s} \d s}
				% \startformula
				% 	B_t = \brnd[B_t - âˆ«_0^t \frac{B_T - B_s}{1 - s} \d s] + âˆ«_0^T \frac{B_T - B_s}{1 - s} \d s
				% \stopformula
			\item  Enlargement of filtration
			\item  White noise theory
			\item  Malliavin calculus
			\item  â€¦

				% \m{B_t = \brnd[B_t - âˆ«_0^t \frac{B_T - B_s}{1 - s} \d s] + âˆ«_0^T \frac{B_T - B_s}{1 - s} \d s}
		\stopitemize

	\stopitemize
\stopslide

\startslide [title={The new integral \cite[short][AyedKuo2008, AyedKuo2010]}: Idea]

	\startitemize[1]

		\item  A process \m{Y^{\argdotsup}} and filtration \m{â„±_{\argdotsub}} are called \important{instantly independent} if \m{Y^t} and \m{â„±_t} are independent \m{âˆ€ t}.

			Example: The process \m{(B_T - B_{\argdotsub})} is instantly independent of the filtration generated by \m{B_{\argdotsub}}.

		\item  Ideas
			\startitemize[n, joinedup]

				\item  Decompose the integrand into \good{adapted} and \okay{instantly independent} parts.

				\item  Evaluate the \good{adapted} and the \okay{instantly independent} parts at the \good{left} and \okay{right} endpoints.

			\stopitemize

		\item  Consider two continuous stochastic processes, \good{\m{X_t} adapted} and \okay{\m{Y^t} instantly independent} w.r.t. \m{â„±_{\argdotsub}}. Then the integral \m{âˆ«_0^T \good{X_t} \okay{Y^t} \d B_t} is \important{defined} as
			\startformula
				âˆ«_0^T \good{X_t} \okay{Y^t} \d B_t  â‰œ  \lim_{\norm[Î”_n] â†’ 0}  âˆ‘_{j = 0}^{n - 1} \good{X_{t_{j}}} \okay{Y^{t_{j+1}}} Î”B_j ,
			\stopformula
			provided that the limit exists in probability.

		\item  Now, for any stochastic process \m{Z(t) = âˆ‘_{k = 1}^n \good{X_t^{(k)}} \okay{Y^t_{(k)}}} we extend the definition by linearity.

		\item  This is well-defined \cite[short][HwangKuoSaitÃ´Zhai2016].
		%\m{âˆ«_0^T Z(t) \d B_t = âˆ‘_{k = 1}^n âˆ«_0^T Z(t) X_t^{(k)} Y^t_{(k)} \d B_t}.
		% \startformula
		% 	âˆ«_0^T Z(t) \d B_t = âˆ‘_{k = 1}^n âˆ«_0^T \good{X_t^{(k)}} \okay{Y^t_{(k)}} \d B_t
		% \stopformula

	\stopitemize
\stopslide

\startslide [title={A simple example}]

	\startitemize [4]

		\item  	In the following, denote \m{Î” B_j = B_{t_{j+1}} - B_{t_j}} and \m{\lim} is the limit in \m{L^2}.
			\startformula \startalign
				\NC  âˆ«_0^t B_T \d B_t
					\NC =  âˆ«_0^t (\good{B_t} + \okay{(B_T - B_t)}) \d B_t
					    =  \good{âˆ«_0^t B_t \d B_t}  +  \okay{âˆ«_0^t (B_T - B_t) \d B_t}
				\NR \NC
					\NC =  \good{\lim âˆ‘_{j = 0}^{n - 1} B_{t_j} Î” B_j}
						+  \okay{\lim âˆ‘_{j = 0}^{n - 1} (B_T - B_{t_{j + 1}}) Î” B_j}
				\NR \NC
					\NC =  \lim âˆ‘_{j = 0}^{n - 1} \brnd[B_T - Î” B_j] Î” B_j
				\NR \NC
					\NC =  B_T \lim âˆ‘_{j = 0}^{n - 1} Î” B_j - \lim âˆ‘_{j = 0}^{n - 1} (Î” B_j)^2
					    =  B_T B_t - t
			\stopalign \stopformula

		\item  Note that \m{ğ”¼(B_T B_t - t) = 0}.

		\item  In general, \m{ğ”¼ âˆ«_0^t Z(s) \d B_s = 0}. \good{\smile}
	\stopitemize
\stopslide

\startslide [title={A generalized ItÃ´ formula \cite[short][HwangKuoSaitÃ´Zhai2016]}]

	\starttabulate [|c|m|m|]
		\NC  Process
		\NC  \text{Definition}
		\NC  \text{Representation}

		\NR
		\FL

		\NC  \good{ItÃ´}
		\NC  \good{X_t = X_0 + âˆ«_0^t m_s \d s + âˆ«_0^t Ïƒ_s \d B_s}
		\NC  \good{\d X_t = m_t \d t + Ïƒ_t \d B_t}

		\NR

		\NC  \okay{instantly independent}
		\NC  \okay{Y^t = Y^0 + âˆ«_t^T Î·^s \d s + âˆ«_t^T Ï‚^s \d B_s}
		\NC  \okay{\d Y^t = - Î·^t \d t - Ï‚^t \d B_t}

		\NR
		\BL
	\stoptabulate

	\starttheorem[title={\cite[short][HwangKuoSaitÃ´Zhai2016]}]
		Let \good{\m{\d X_t = m_t \d t + Ïƒ_t \d B_t}} be an \m{d}-dimensional \good{ItÃ´} process, \okay{\m{\d Y^t = - Î·^t \d t - Ï‚^t \d B_t}} be a \m{\tilde{d}}-dimensional \okay{instantly independent} process.
		If \m{f(x, y) âˆˆ C^2(â„^2)}, then
		\startformula \startalign
				\NC \d f(X_t, Y^t)  =
				\NC \good{\inn[(\D_x f) (X_t, Y^t), \d X_t]
					+ \frac12 \inn[\d X_t, (D_x^2 f)(X_t, Y^t) \, \d X_t]}
			\NR \NC
				\NC + \okay{\inn[(\D_y f) (X_t, Y^t), \d Y^t]
					- \frac12 \inn[\d Y^t, (D_y^2 f)(X_t, Y^t) \, \d Y^t]} ,
		\stopalign \stopformula
		where we use the rules \important{\m{\d B_t âŠ— \d B_t = I_d \d t}}.
	\stoptheorem
\stopslide

\startslide [title={Exponential processes and a generalized Girsanov theorem}]

	\startitemize [4]

		\item  TODO

	\stopitemize
\stopslide


\startslide [title={Iterated integrals}]

	\starttheorem[title={\cite[short][ItÃ´1951MWI]}]
		Let \m{f âˆˆ L^2([0, T]^n)} and \m{\bad{\hat{f}}} be its symmetrization. Then
		\startformula
			âˆ«_{[0, T]^n} f(t_1, â€¦, t_n) \d B_{t_1} â€¦ \d B_{t_n}  =  \bad{n!} âˆ«_0^T â‹¯ âˆ«_0^{\bad{t_{n-2}}} \brnd[âˆ«_0^{\bad{t_{n-1}}} \bad{\hat{f}}(t_1, â€¦, t_n) \d B_{t_n}] \d B_{t_{n-1}} â€¦ \d B_{t_1} .
		\stopformula
		% \m{\hat{f}(t_1, â€¦, t_n)  =  \frac{1}{n!} âˆ‘_{Ïƒ âˆˆ S_n} f(t_{Ïƒ(1)}, â€¦, t_{Ïƒ(n)})}
	\stoptheorem

	\starttheorem[title={\cite[short][AyedKuo2010]}]
		Let \m{f âˆˆ L^2([0, T]^n)}. Then
		\startformula
			âˆ«_{[0, T]^n} f(t_1, â€¦, t_n) \d B_{t_1} â€¦ \d B_{t_n}  =  âˆ«_0^T â‹¯ âˆ«_0^T f(t_1, â€¦, t_n) \d B_{t_n} â€¦ \d B_{t_1} .
		\stopformula
	\stoptheorem

	Example\cite[short][HwangKuoSaitÃ´Zhai2016]: In the new integral, \m{âˆ«_0^T âˆ«_0^T B_s \d B_s \d s = âˆ«_0^T âˆ«_0^T B_s \d s \d B_s}.
\stopslide

\startslide [title={Near-martingale property \cite[short][HwangKuoSaitÃ´Zhai2017]}]

	\startitemize [4]

		\item  Question: What are the analogues of the martingale property and the Markov property?

		\item  Answer for martingales: \quotation{near-martingales}.

		\item  Let \m{Z(t)} be a stochastic process such that \m{ğ”¼\abs[Z(t)] < âˆ \ âˆ€ t}, and \m{0 â‰¤ s â‰¤ t â‰¤ T}. Then, with respect to \m{â„±_{\argdotsub}}, the process \m{Z(t)} is called a
			\startitemize [5, joinedup]
				\item  \important{near-martingale} if \m{ğ”¼(Z(t) âˆ£ â„±_s) = ğ”¼(Z(s) âˆ£ â„±_s)},
				\item  \important{near-submartingale} if \m{ğ”¼(Z(t) âˆ£ â„±_s) â‰¥ ğ”¼(Z(s) âˆ£ â„±_s)}, and
				\item  \important{near-supermartingale} if \m{ğ”¼(Z(t) âˆ£ â„±_s) â‰¤ ğ”¼(Z(s) âˆ£ â„±_s)}.
			\stopitemize

	\stopitemize

	\starttheorem %[title={\cite[short][HwangKuoSaitÃ´Zhai2017]}]
		Let \m{Z(\argdotmid)} be a stochastic process bounded in \m{L^1}, and \m{X_{\argdotsub} = ğ”¼(Z(\argdotmid) âˆ£ â„±_{\argdotsub})}. Then \m{X_{\argdotsub}} is a (\good{sub}/\bad{super})martingale if and only if \m{Z(\argdotmid)} is a near-(\good{sub}/\bad{super})martingale.
	\stoptheorem

\stopslide

\stopmode

\stopsection

\page    % Needed for correct color transition



%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Large deviations theory %
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setupbackgrounds [page] [
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-2}]
\startcolor [\getvariable{document}{color-foreground-2}]    % text color

\startsection [title={Large deviations theory}, reference=sec:large-deviations-theory]

\startmode [presentation]

\startslide[title={What is it about?}]

	\startitemize [4]

		\item  A theory to find probabilities of rare events that decay exponentially.

		\item  Started by Swedish actuarials Fredrik Esscher, Harald CramÃ©r, Filip Lundberg.

		\item  Unified by Varadhan in his 1966 paper \cite[short][Varadhan1966].

		\item  Example: A problem faced by the insurance industry.
			\startitemize [5, joinedup]
				\item  Value of claims received on the \m{n}th day: \m{X_n} \$.
				\item  Steady income from premium: \m{x} \$/day.
				\item  Planning period: \m{n} days.
				\item  Average expenditure: \m{\overline{X}_n = \frac1n âˆ‘_{j = 1}^n X_j} \$/day.
				\item  \emph{Question}: How should the company decide on the premium?
				\item  \important\emph{Idea}: {Determine \m{x} such that \m{â„™\bcrl[\overline{X}_n > x] < Îµ} (specified)}.
			\stopitemize
	\stopitemize
\stopslide

\startslide [title={Insurance problem: setup}]

	\startitemize [n]
		\item  Let the following hold:
			\startitemize [5, joinedup]
				\item  \m{(Î©, â„±, â„™)} is a probability space.
				\item  \m{(X_n)} is a sequence of i.i.d. random variables on \m{(Î©, â„±, â„™)} with finite moment generating function \m{M}.
				\item  \important{\m{ğ”¼ X_1 = m}}, \m{ğ• X_1 = Ïƒ^2}, and \m{X_1 âˆ¼ Î¼}.
				\item  \m{\overline{X}_n = \frac1n âˆ‘_{j = 1}^n X_j}.
			\stopitemize

		\item  Asymptotic behavior of \m{\overline{X}_n}:
			\startitemize [5, joinedup]
				\item  \important{Weak law of large numbers: \m{\overline{X}_n \xrightarrow{â„™} m}}.
				\item  Central limit theorem: \m{\sqrt{n} (\overline{X}_n - m) \xrightarrow{ğ““} ğ“(0, Ïƒ^2)}.
			\stopitemize

		\item  What is the rate for LLN?

		% \item  We want to \quotation{control large deviations from the mean}.
	\stopitemize
\stopslide

\startslide [title={Insurance problem: large deviation bounds}]

	\startitemize [n]
		\item  For \m{x > m} and an arbitrary \m{Î¸ > 0}, we get
			\startformula
				â„™\bcrl[\overline{X}_n â‰¥ x]
				=  â„™\bcrl[e^{Î¸n\overline{X}_n} â‰¥ e^{Î¸nx}]
				â‰¤  e^{-Î¸nx} ğ”¼\brnd[e^{Î¸n\overline{X}_n}]
				=  e^{-Î¸nx} M_{X}(Î¸)^n
				=  e^{-n(Î¸x - \log M_{X}(Î¸))} .
			\stopformula

		\item  Since \m{Î¸} was arbitrary, we have
			\startformula
				â„™\bcrl[\overline{X}_n â‰¥ x]
				â‰¤  \inf_Î¸ e^{-n(Î¸x - \log M_{X}(Î¸))}
				=  e^{-n \sup_Î¸ (Î¸x - \log M_{X}(Î¸))}
				=: e^{-n I(x)} .
			\stopformula

		\item  Generalizing, we get the \important{large deviation upper bound}
			\startformula
				\important{\limsupm \frac1n \log â„™\bcrl[\overline{X}_n âˆˆ F]  â‰¤  -\inf_F I  \qquad  âˆ€ F \text{ closed}} .
			\stopformula

		\item  We can also obtain a \important{large deviation lower bound} using an exponential change of measure
			\startformula
				\important{\liminfm \frac1n \log â„™\bcrl[\overline{X}_n âˆˆ G]  â‰¥  -\inf_G I  \qquad  âˆ€ G \text{ open}} .
			\stopformula

		\item  We (in)formally write \m{â„™\bcrl[\overline{X}_n âˆˆ \d x] â‰ e^{-n I(x)} \d x} for \m{x âˆˆ â„}.
	\stopitemize
\stopslide

\startslide [title={Definition of large deviation principle}]

	\startitemize [4]

		\item  The setup: \m{(X_n)} is a stochastic process on \m{(Î©, â„±, â„™)} taking values in a Polish space \m{(ğ“§, d)}.

		\item  A function \m{I: ğ“§ â†’ [0, âˆ]} is called a \important{rate function} if it has compact level sets.

		% \item  \m{I} is lower semicontinuous and attains its infimum on every nonempty closed set.

		% \item  For any Borel set \m{E}, denote \m{I(E) = \inf I(x)}.
	\stopitemize

	\startdefinition
		\m{(X_n)} is said to satisfy the \important{large deviation principle on \m{ğ“§} with rate function \m{I}} if the large deviation \okay{upper} and \okay{lower} bounds hold.
		% \startformula \startalign[n=4]
		% 	\NC  \text{(upper bound)}  \qquad  \NC  \limsupm \frac1n \log â„™\bcrl[\overline{X}_n âˆˆ F]  \NC â‰¤  -\inf_{F} I  \NC  \qquad  âˆ€ F \text{ closed}  \NR
		% 	\NC  \text{(lower bound)}  \qquad  \NC  \liminfm \frac1n \log â„™\bcrl[\overline{X}_n âˆˆ G]  \NC â‰¥  -\inf_{G} I  \NC  \qquad  âˆ€ G \text{ open}
		% \stopalign \stopformula
	\stopdefinition

	Example
	\starttheorem [title={\cite[short][CramÃ©r1938]}]
		Let \m{(X_n)} be a sequence of i.i.d. real random variables with finite moment generating function \m{M}. Then \m{(X_n)} follows large deviation principle with rate function \m{I(x) = \sup_Î¸ \brnd[Î¸ x - \log M(Î¸)]}.
	\stoptheorem
\stopslide

\startslide [title={Applications of the CramÃ©r theorem}]

	Rate functions for some common distributions
	% \placetable[force,none]{}{%    % This centers the table
	\starttabulate [|M|M|M|]
		\FL
		\NC  \text{Distribution}  \NC  M(Î¸)  \NC  I(x)  \NR
		\FL
		\NC  \text{Bernoulli}(p)  \NC  1 - p + p e^Î¸  \NC  \brnd[x \log x + (1-x) \log(1-x) - {\brnd[x \log \frac{1-p}{p} + \log{p}]}] ğŸ™_{[0, 1]}(x) + âˆ ğŸ™_{[0, 1]^âˆ}(x)  \NR \NR
		\NC  \text{Poisson}(Î»)  \NC  e^{Î»(e^Î¸ - 1)}  \NC  \brnd[Î» - x + x \log \frac{x}{Î»}] ğŸ™_{[0, âˆ)}(x) + âˆ ğŸ™_{(-âˆ, 0)}(x)  \NR \NR
		\NC  Exp(Î»)   \NC  \inv[{\brnd[1 - \frac{Î¸}{Î»}]}]  \NC  \brnd[Î»x - 1 + x \log(Î» x)] ğŸ™_{[0, âˆ)}(x) + âˆ ğŸ™_{(-âˆ, 0)}(x)  \NR \NR
		\NC  ğ“(m, Ïƒ^2)  \NC  e^{m Î¸ + \frac12 Ïƒ^2 Î¸^2}  \NC  \frac{(x - m)^2}{2 Ïƒ^2}  \NR \NR
		\NC  Ï‡^2(k)  \NC  (1 - 2 Î¸)^{-\frac{k}{2}}  \NC  \frac12 \brnd[x - k + k \log\frac{k}{x}]  \NR
		\BL
	\stoptabulate%}
	% ToDo: Add more.
	% ToDo: Add the computation in the appendix.
\stopslide

\startslide [title={The Schilder theorem}]

	\startitemize [4]

		\item  Aim: Estimate the probability that a scaled-down sample path of a \important{Brownian motion} will stray far from the mean path.

		\item  Let \m{B_{\argdotsub}} be a \m{d}-dimensional Brownian motion, so \m{B_{\argdotsub} âˆˆ C_0 = C_0([0, T]; â„^d)}

		\item  \m{âˆ€ Îµ > 0}, let \m{\sqrt{Îµ} B_t âˆ¼ W^{(Îµ)}}. Then \m{W^{(Îµ)} = ğ“(0, Îµ t) \xrightarrow{ğ““} Î´_0} as \m{Îµ â†’ 0}.
		% This scales down the variance of the Brownian motion to \m{Îµ t}.

		\item  Let \m{\text{CM} = \bcrl[Ï‰ âˆˆ C_0 : Ï‰ \text{ is absolutely continuous and } Ï‰_t' âˆˆ L^2{[0, T]}]}.
	\stopitemize

	\starttheorem [title={\cite[short][Schilder1966]}]
		On the Banach space \m{\brnd[C_0, {\norm[â‹…]}_âˆ]}, the family of probability measures \m{\bcrl[W^{(Îµ)} : Îµ > 0]} satisfies LDP with the rate function \m{I : C_0 â†’ \clsr[â„]} given by
		\startformula
			I(Ï‰)  =  \brnd[\frac12 âˆ«_0^T {\abs[Ï‰_t']}^2 \d t] ğŸ™_{\text{CM}}(Ï‰) + âˆ ğŸ™_{\text{CM}^âˆ}(Ï‰)
		\stopformula
	\stoptheorem
\stopslide

\startslide [title={The Freidlinâ€“Wentzell theorem}]

	\startitemize [4]

		\item  Aim: Estimate the probability that a scaled-down sample path of an \important{ItÃ´ diffusion} will stray far from the mean path.

		\item  \m{âˆ€ Îµ > 0}, let \m{X^{(Îµ)}_{\argdotsub}} be the solution of the \m{d}-dimensional stochastic differential equation

			\important{\m{\d X^{(Îµ)}_t = m(X^{(Îµ)}_t) \d t + \sqrt{Îµ} Ïƒ(X^{(Îµ)}_t) \d B_t , \ X^{(Îµ)}_0 = x}},
			where \m{m, Ïƒ} are sufficiently nice.

		\item  Let \m{W^{(Îµ)}_x} denote the law of \m{X^{(Îµ)}_{\argdotsub}} starting at \m{x}.

		\item  As \m{Îµ â†’ 0}, \m{W^{(Îµ)}_x \xrightarrow{ğ““} Î´_Î¾}, where \m{Î¾} solves the ODE \m{\dot{Î¾}(t) = m(Î¾(t)), \ Î¾(0) = x}.

		\item  Let \m{\text{CM}_x = \bcrl[Ï‰ âˆˆ C_x : Ï‰ \text{ is absolutely continuous and } Ï‰_t' âˆˆ L^2{[0, T]}]}.
	\stopitemize

	% Generalizes the Schilder theorem for ItÃ´ diffusions.

	\starttheorem
		For \m{x} fixed, the family of probability measures \m{\bcrl[W^{(Îµ)}_x : Îµ > 0]} satisfies LDP with the rate function \m{I_x : C_0 â†’ \clsr[â„]} given by
		\startformula
			I_x(Ï‰)  =  \brnd[\frac12 âˆ«_0^T {\inn[Ï‰_t' - b(Ï‰_t), {\inv[A](Ï‰_t)}{\brnd[Ï‰_t' - b(Ï‰_t)]}]} \d t] ğŸ™_{\text{CM}_x}(Ï‰) + âˆ ğŸ™_{\text{CM}_x^âˆ}(Ï‰) ,
		\stopformula
		where \m{A = Ïƒ Ïƒ^*}.
	\stoptheorem
\stopslide

\stopmode

\stopsection

\page    % Needed for correct color transition



%%%%%%%%%%%%%%
% Conclusion %
%%%%%%%%%%%%%%

\setupbackgrounds [page] [
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-0}]
\startcolor [\getvariable{document}{color-foreground-0}]    % text color

\startsection [title={Futher research}, reference=sec:directions]


\startmode [presentation]

\startslide [title={Possible research directions}]

	\startcolor [\getvariable{document}{color-foreground-1}]    % text color
	\startitemize [4]
		\item  Develop the near-Markov property for the new integral.

		\item  Formulate the extension to stochastic differential equations with anticipating coefficients.

		\item  Identify the class of integrable processes under the new integral.

		\item  Give a broader generalization of the Girsanov theorem.
	\stopitemize

	\startcolor [\getvariable{document}{color-foreground-2}]    % text color
	\startitemize [4]

		\item  Prove Freidlinâ€“Wentzell type results for stochastic differential equations with anticipation.

		\item  Study LDP results for SDEs with anticipating coefficients.

		\item  Analyze LDP for linear SPDEs with anticipating initial conditions.
	\stopitemize
\stopslide

\startslide

\startalign [middle]

	\blank[4*line]

	{\tfd Thank you!}

\stopalign
\stopslide

\startslide [title={Laplace principle and equivalence to LDP}]

	\startdefinition [title={Laplace principle}]
		\m{(X_n)} is said to satisfy the \important{Laplace principle on \m{ğ“§} with rate function \m{I}} if for all bounded continuous functions \m{h}, we have
		\startformula
			\lim  \frac1n \log ğ”¼\exp(-n h(X_n))  =  \inf_ğ“§ (h + I)
		\stopformula
	\stopdefinition

	\starttheorem
		\m{(X_n)} satisfies LP on \m{ğ“§} with rate function \m{I} if and only if \m{(X_n)} satisfies LDP on \m{ğ“§} with the same rate function \m{I}.
	\stoptheorem

	\bold{Some important results}
	\startitemize [5, nowhite]
		\item  Uniqueness of the rate function.
		\item  Continuity principle.
			% Let \m{f:ğ“§ â†’ ğ“¨} be a continuous map of Polish spaces. Then \m{(f(X_n))} satisfies Laplace principle with rate function \m{J(y) = \inf \bcrl[I(x): x âˆˆ {\inv[f]}(y)]}.
		\item  Superexponential approximation preserves Laplace principle.
		  % If \m{(Y_n)} is superexponentially close to \m{(X_n)}, then \m{(Y_n)} satisfies Laplace principle with the same rate function \m{I}.
	\stopitemize
\stopslide

\startslide[title={An application of Schilder theorem}]

	\startitemize [4]

		\item  \m{W\brnd[C_0 âˆ– B_r(0)] = \bcrl[{\norm[B_{\argdotsub}]}_âˆ > r]}

		\item  \m{\bcrl[{\norm[B_{\argdotsub}]}_âˆ > r]}
	\stopitemize
\stopslide

\startslide[title={Using the continuity principle to extend the Schilder theorem}]
	TODO
\stopslide

\startslide [title={Sanov theorem}]

	\startitemize [4]

		\item  \bold{Aim}: Provide a bound on the probability of observing an atypical sequence of samples from a given probability distribution.

		\item
	\stopitemize
\stopslide

\stopmode

\stopsection

\stopbodymatter




%%%%%%%%%%%%%%%
% Back matter %
%%%%%%%%%%%%%%%

\startbackmatter
\startmode [presentation]
\startslide [title={Bibliography}]
	\placelistofpublications
\stopslide
\stopmode
\stopbackmatter

\stoptext
